{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53a70ff1-5d3b-48ea-9e90-71f2a233c688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import wisardpkg as wp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b53e4d19-d914-4fe4-beb3-af9aaa269442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#descompactar o zip\n",
    "if len(os.listdir('./dataset')) <= 2: \n",
    "    !unzip -qq ./dataset/HAR.zip -d ./dataset/HAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9949cf93-90d1-4deb-b838-06179d2d6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(filenames, labels, folder):\n",
    "    images = []\n",
    "    for filename in filenames:\n",
    "        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (28, 28))  # Reescalona a imagem para 28 x 28. Experimentem com outros tamanhos\n",
    "            images.append(img.flatten())  # Achata a imagem\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b11a2ae9-f44c-4c18-ba44-2a6e650287b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './dataset/HAR/Human_Action_Recognition/'\n",
    "train_df = pd.read_csv(root_path + 'Training_set.csv')\n",
    "\n",
    "# Filtros para classes de interesse\n",
    "classes_of_interest = ['hugging', 'running', 'texting', 'fighting']\n",
    "filtered_df = train_df[train_df['label'].isin(classes_of_interest)]\n",
    "\n",
    "train_folder = root_path + 'train'\n",
    "\n",
    "# Carrega as imagens do dataset filtrado\n",
    "train_images = load_images(filtered_df['filename'].tolist(), filtered_df['label'].tolist(), train_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a538abd1-02dc-4e90-b0ca-024a4ef4931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarização\n",
    "train_images_binary = [list(map(int, np.round(img / 255))) for img in train_images]\n",
    "\n",
    "# Rótulos\n",
    "train_labels = filtered_df['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "541f48cf-1463-46f1-9960-c70e537215bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_images_binary, train_labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "835c0282-73ea-4d1c-af9e-73f88ad85f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bits_addr = 14\n",
    "model = wp.Wisard(num_bits_addr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a16a3af-e544-4175-9fdf-2a78b059b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bb75c9c-35e0-4bc8-a6a8-77ec4150853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.44345238095238093\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.classify(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('acc: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
